---
title: 'Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework'
authors:
  - Rui Yao
  - Qi Chai
  - Jinhai Yao
  - admin
  - Junhao Chen
  - Qi Zhang
  - Hao Wang
author_notes:
  - 'Equal contribution'
  - 'Equal contribution'
  - 'Equal contribution'
  - ''
  - ''
  - ''
  - ''
date: '2025-08-12T00:00:00Z'
doi: ''
publishDate: '2025-01-01T00:00:00Z'
publication_types: ['paper-conference']
publication: In *arXiv preprint*
publication_short: In *arXiv*
abstract: '"Fedspeak", the stylized and often nuanced language used by the U.S. Federal Reserve, encodes implicit policy signals and strategic stances. The Federal Open Market Committee strategically employs Fedspeak as a communication tool to shape market expectations and influence both domestic and global economic conditions. As such, automatically parsing and interpreting Fedspeak presents a high-impact challenge, with significant implications for financial forecasting, algorithmic trading, and data-driven policy analysis. In this paper, we propose an LLM-based, uncertainty-aware framework for deciphering Fedspeak and classifying its underlying monetary policy stance. Technically, to enrich the semantic and contextual representation of Fedspeak texts, we incorporate domain-specific reasoning grounded in the monetary policy transmission mechanism. We further introduce a dynamic uncertainty decoding module to assess the confidence of model predictions, thereby enhancing both classification accuracy and model reliability. Experimental results demonstrate that our framework achieves state-of-the-art performance on the policy stance analysis task.'
summary: An LLM-based uncertainty-aware framework for interpreting Federal Reserve communications with enhanced reliability.
tags:
  - Federal Reserve
  - Monetary Policy
  - Large Language Models
  - Uncertainty Quantification
featured: true
links:
  - name: ArXiv
    url: https://arxiv.org/abs/2508.08001
url_pdf: 'https://arxiv.org/pdf/2508.08001.pdf'
url_code: 'https://github.com/yuuki20001/FOMC-sentiment-path'
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''
image:
  caption: 'Fedspeak Analysis Framework'
  focal_point: ''
  preview_only: false
projects: []
slides: ""
---

## Abstract

This paper proposes an LLM-based uncertainty-aware framework for interpreting Federal Reserve communications (Fedspeak) and classifying monetary policy stance. The framework incorporates domain-specific reasoning grounded in monetary policy transmission mechanisms and introduces dynamic uncertainty decoding to assess prediction confidence.

## Methodology

- **Domain Knowledge Integration**: Incorporates monetary policy transmission mechanism knowledge
- **Uncertainty Quantification**: Decomposes perceptual uncertainty into cognitive risk and environmental ambiguity
- **Dynamic Decoding**: Adaptively selects decoding strategies based on model confidence levels

## Results

The framework achieves competitive performance on policy stance analysis tasks, with uncertainty measures providing reliability indicators for predictions.